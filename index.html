<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ICDAR 2019 - CHART Competition</title>
  <meta name="description" content="ICDAR 2019 CHART HARVESTING Competition">
  <!--<meta name="author" content="">-->
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <script src="js/main.js"></script>
  <div class="main">
	<div class="title">
		<a href="http://icdar2019.org/" target="_blank">
			<h2><b style="color: rgb(243,102,35);">ICDAR </b> 2019</h2>
		</a>
		<h1 align="center"><b style="color: rgb(243,102,35);">C</b>ompetition on <b style="color: rgb(243,102,35);">Ha</b>rvesting <b style="color: rgb(243,102,35);">R</b>aw <b style="color: rgb(243,102,35);">T</b>ables from Infographics </h1>		
		
		<table style="margin:auto;">
			<tr>
				<td><img src="img/quick_line_chart.png" width="180px"></td>
				<td><h1 align="center"><b style="color: rgb(243,102,35);">CHART</b>-Infographics 2019</h1></td>
				<td><img src="img/quick_bar_chart_solid.png" width="180px"></td>
			</tr>
		</table>		
	</div>	
	<div class="menu">
		<table>
			<tr style="cursor: pointer;font-size: 18pt">
				<td onclick="update_view('home');">Home</td>
				<td onclick="update_view('tasks');">Tasks</td>
				<td onclick="update_view('schedule');">Schedule</td>
				<td onclick="update_view('data_tools');">Tools and Data</td>
				<td onclick="update_view('contact');">Contact Us</td>
			</tr>
		</table>
	</div>
	<div class="content">
		<div id="home" style="display: None;">
			<h1>Summary</h1>
			<p>
			This competition is composed of a series of 7 sub-tasks for chart data extraction, which when put together as a pipeline go from an input chart image to a CSV file representing the data used to create the chart.
			Entrants in the competition may choose to participate in any number of sub-tasks, which are evaluated in isolation, such that solving previous sub-tasks is not necessary.
			We hope that such decomposition of the problem of chart data extraction will draw broad participation from the Document Analysis and Recognition (DAR) community.
			Additionally, we also evaluate methods that perform the whole chart data extraction pipeline.
			</p>
			<h2>Background</h2>
			<p>
				Charts are a compact method of displaying and comparing data. In scientific publications, charts and graphs are often used to to summarize results, comparison of methodologies, emphasize the reasoning behind key aspects of the scientific process, and  justification of design choices, to name a few. Automatically extracting data from charts is a key step in understanding the intent behind a chart which could lead to a better understanding of the document itself. 
			</p>
			<table style="margin: auto;">
				<tr>
					<td><img src="img/charts.png" width="600px"></td>
				</tr>
				<tr>
					<td style="font-size: 10pt; text-align: center;">Example chart types to use in the proposed competition. Note that all these were generated from the same tabular data.</td>
				</tr>
			</table>
			
			<p>
				The DAR community has displayed a continued interest in classifying types of charts as well as processing charts to extract data. In the past decade, multiple applications have been built around automatic processing of charts such as retrieval, textual summarization of charts, making charts more accessible on the web, automatically redesigning charts, automatically assessing chart quality, preservation of charts from historical documents, chart data plagiarism detection, bibliometrics, visual question answering and accelerating discovery of new materials.
			</p>
			<p>
				Prior competitions related to this area include DeTEXT which concentrated on detecting text in figures and ImageCLEF competition on medical compound figure separation and multi-label classification. However, these competitions do not concentrate on end-to-end data extraction from scientific charts, but include these as a sub-type of scientific figures in general. 
			</p>
			
			<h2>Competition Outline</h2>
			<p>
			Both synthetic (created with matplotlib) and real charts (harvested from <a href='https://www.ncbi.nlm.nih.gov/pmc/'>PubMedCentral</a>) are provided as training data.
			Near the end of the competition, we will release test data, and competition participants are expected to send in 1) Method results on the test data 2) Summary of method 3) runnable code that can reproduce the results.
			The organizers will tabulate the overall results and the results for each sub-task to be presented at ICDAR 2019.
			</p>

			<p> The sub-tasks considered in this competition are </p>
				<ol>
					<li> Chart Image Classification (e.g. bar, box, line) </li>
					<li> Text Detection and Recognition </li>
					<li> Text Role Classification (e.g. title, x-axis label) </li>
					<li> Axis Analysis </li>
					<li> Legend Analysis </li>
					<li> Plot Area Analysis </li>
					<li> Data Extraction </li>
				</ol>
			<p> 
			Each subtask is evaluated in isolation, meaning that methods will have access to the ideal output (i.e. Ground Truth) of previous subtasks.
			For example, the input for the Axis Analysis sub-task is the chart image, chart type, and the text bounding boxes, transcriptions and roles.
			Each sub-task has its own evaluaton metric.
			</p>
			<p> Additionally, methods may be submitted for the complete data extraction task where subtasks 1-7 are performed together.  </p>

			<h2>Registration</h2>
			<p> To register, please send an email to chartinfo.icdar2019@gmail.com.  Please include the following. </p>
				<ul>
					<li> Names of participants </li>
					<li> Primary contact person </li>
					<li> Affiliation of participants </li>
					<li> Team Name </li>
					<li> List of tasks you are interested in participating in (you are not restricted to this list) </li>
				</ul>
			<p> Upon registration, you will be sent additional information to obtain the training and test data when it becomes available. </p>

			<!--
			<p>
				This competition is focused on data extraction and key element classification in charts used in scientific documents. More specifically, we have created a benchmark for axes charts (line, area, bar, box, and scatter plots) using a combination of synthetic data and figures from the PubMedCentral open access collection. Additionally, pie charts are considered in one sub-task (classification).

				The competition consists of multiple sub-tasks: chart image classification, extraction of text, text role classification, identifying legend and legend symbols, identifying chart marks such as lines, bars, and scatter marks, and finally extracting tabular data that originally produced the chart. These tasks are independent of each other and could potentially be chained to fulfill the overall task of extraction of tabular data from the chart. Metrics for each individual sub-task are derived from commonly used metrics for detection and classification such as recall-precision and accuracy. End-to-end competing systems will be evaluated on the basis of extraction of tabular data. 
			</p> -->
		</div>
		<div id="tasks" style="display: None;">
			<h1>Competition Tasks</h1>
			<p>
				The main task of the competition is data extraction from axes charts in the form of a table with the correct values that originally generated the graph. This task is divided into several sub-tasks that are important steps along the way. Note that since some partial ground truth will be provided for task with dependencies (text role classification depends on text detection and recognition, data extraction depends on all previous tasks), disjoint subsets of the test set will be used to evaluate these tasks independently for fairness. For most tasks, chart image and type of chart (one of line, area, bar, box or scatter) are provided along with other task-specific inputs.
			</p>
			<h2>1) Chart Image Classification</h2>
			<p> This first sub-task is to classify chart images by type. Given the chart image, methods are expected to output one of the following 11 classes. </p>
			<table style="margin:auto; width:100%; font-size:11pt; text-align:center">
				<tr>
					<td> Pie </td>
					<td> Donut </td>
					<td> Vertical box </td>
					<td> Horizontal box </td>
				</tr><tr>
					<td> Grouped vertical bar </td>
					<td> Grouped horizontal bar </td>
					<td> Stacked vertical bar </td>
					<td> Stacked horizontal bar </td>
				</tr><tr>
					<td> Line </td>
					<td> Area </td>
					<td> Scatter </td>
				</tr>
			</table>

			<h3> Metric </h3>
			<p>
			The evaluation metric will be the average per-class F-measure.
			Based on the class confusion matrix, we can compute the precision, recall, and F-measure for each class.
			The overall score is the average of each classes' F-measure.
			</p>
			<h3> Input/Output </h3>
			<p> Input: Chart Image <p>
			<p> Output: Chart Class <p>

			<h2>2) Text Detection and Recognition</h2>
			<p>
				This sub-task concentrates on detecting and recognizing the text within the chart image. 
				Competing systems are expected to produce tight bounding boxes (at the word level) and transcriptions for text. 
				Distinct alphanumeric and numeric sequences are treated as individual words. 
				A predicted bounding box matches a GT bounding box if their Intersection Over Union (IOU) is at least 0.5, 
					and tighter IOU criteria will be used to resolve ties when multiple predictions can match a single GT bounding box.
				<!-- Evaluation metrics for detection of bounding boxes is precision-recall at Intersection Over Union (IOU) of 0.5. Tighter IOU criteria will be used to resolve ties. Same procedure as the ICDAR Robust Reading Competitions will be used to handle split/merged boxes. Transcription errors will be compared on the basis of edit distance from ground truth. -->
			</p>
			<h3> Metric </h3>
			<p> Average normalized Character Error Rate (CER) for each word plus (1 - IOU).
				By normalized CER, we mean that the number of character edits to transform a predicted word to GT word is divided by the length of the GT word.  
				False positive and false negative word detections will be assigned a normalized CER of 1 and an IOU of 0 to incur the maximum penalty of 2.  
				We will use the same procedure as the ICDAR Robust Reading Competitions to handle split/merged boxes.
			</p>
			<p>
				For each chart, we will compute the average score for all words in that chart.
				Then we will average the per-chart scores over the whole dataset to ensure that each image contributes equally to the final score.
			</p>
			<h3> Input/Output </h3>
			<p> Input: Chart Image, Chart Class <p>
			<p> Output: List of Word Bounding Boxes paired with Transcriptions </p>

			<h2>3) Text Role Classification</h2>
			<p>
				This sub-task focuses on identifying the <i>roles</i> of text in a chart image, and text bounding boxes and transcripts are provided.
				Competing systems are expected to classify each bounding box into any of the following roles.
			</p>
			<table style="width:100%; font-size:11pt; text-align:center; align:center">
				<tr>
					<td> Chart title </td>
					<td> X-axis title </td>
					<td> Y-axis title </td>
				</tr><tr>
					<td> X-axis values (tick labels) </td>
					<td> Y-axis values (tick labels) </td>
					<td> Legend title </td>
				</tr><tr>
					<td> Legend label </td>
					<td> Plot label </td>
					<td> Other text </td>
				</tr>
			</table>
			<h3> Metric </h3>
			Similar to the evaluation in sub-task 1 (chart classification), the evaluation metric will be the average per-class F-measure.

			<h3> Input/Output </h3>
			<p> Input: Chart Image, Chart Class, List of Text Bounding Boxes and paired Transcriptions <p>
			<p> Output: Text role (class) for each Bounding Box </p>

			<h2>4) Axis Analysis</h2>
			<p>
				Competing systems are expected to output tight bounding box containing the axis, as well sets containing X and Y axis ranges (or X-axis values in case of bar charts). Evaluation will be on the basis of Intersection Over Union of ground truth axis box and ground truth axes value sets.
			</p>
			<h2>5) Legend Analysis</h2>
			<p>
				Competing systems are expected to output a list of matched pairs of bounding boxes for markers (within the legend area) and corresponding label transcriptions. A minimum IOU score of 0.5 is required to recall a legend marker and penalty for transcriptions will be in terms of edit distance from ground truth.
			</p>
			<h2>6) Plot Area Analysis</h2>
			<p>
				Given the ground-truth outputs of all previous sub-tasks, segment the plot area into components. These components depend on the type of chart, but include Bar, Line point, Scatter Markers, Boxplot Box, Boxplot Min, Boxplot Max, Boxplot Median, Boxplot Fliers (outlier points). The participants are required to output a set of bounding boxes, where each box is assigned to one of the classes above. The evaluation for each of the classes is straightforward (e.g. 50% IOU w.r.t. ground truth) except for line points. Line and area plots will be handled differently.
			</p>
			<h2>7) Data Extraction</h2>
			<p>
				Given the chart image, type and ground truths of the previous sub-tasks, competing systems are expected to output the table that originally generated the chart. This includes correct row and column headers (for multiple plots in the same figure) and corresponding X and Y axis values. Interval metrics will be used to evaluate the produced ranges for X values. Y values accuracy will be determined using MSE and interpolated data using the ground truth table. For box plots, it is not necessary to reproduce the original data as the plot only shows a statistical summary.  Instead, participants are expected to recover the dataset median, upper and lower quartiles (or min/max), and each outlier shown (if any).
			</p>
			<h2>End-to-End Data Extraction</h2>
			<p>
				This is the main task of the competition and involves data extraction. The competing systems will be evaluated on the metric detailed in the previous sub-task and are free to use their own chart processing procedures.
			</p>
		</div>
		<div id="schedule" style="display: None;">
			<h1>Competition Schedule</h1>
			<p>
				Coming Soon.
			</p>
		</div>
		<div id="data_tools" style="display: None;">
			<h1>Tools and Data</h1>
			<p>
				Coming Soon.
			</p>
		</div>
		<div id="contact" style="display: None;">
			<h1>Registration and Contact Information</h1>
			<p>
				For any inquiries, please email us at chartinfo.icdar2019@gmail.com.
			</p>

			<h2>Registration</h2>
			<p> To register, please send an email to chartinfo.icdar2019@gmail.com.  Please include the following. </p>
				<ul>
					<li> Names of participants </li>
					<li> Primary contact person </li>
					<li> Affiliation of participants </li>
					<li> Team Name </li>
					<li> List of tasks you are interested in participating in (you are not restricted to this list) </li>
				</ul>
			<p> Upon registration, you will be sent additional information to obtain the training and test data when it becomes available. </p>

			<h2> Organizer Information </h2>
		</div>
	</div>
  </div>
  <script>
	update_view("home");
  </script>
</body>
</html>
