<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ICDAR 2019 - CHART Competition</title>
  <meta name="description" content="ICDAR 2019 CHART HARVESTING Competition">
  <!--<meta name="author" content="">-->
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <script src="js/main.js"></script>
  <div class="main">
	<div class="title">
		<a href="http://icdar2019.org/" target="_blank">
			<h2><b style="color: rgb(243,102,35);">ICDAR </b> 2019</h2>
		</a>
		<h1 align="center"><b style="color: rgb(243,102,35);">C</b>ompetition on <b style="color: rgb(243,102,35);">Ha</b>rvesting <b style="color: rgb(243,102,35);">R</b>aw <b style="color: rgb(243,102,35);">T</b>ables from Infographics </h1>		
		
		<table style="margin:auto;">
			<tr>
				<td><img src="img/quick_line_chart.png" width="180px"></td>
				<td><h1 align="center"><b style="color: rgb(243,102,35);">CHART</b>-Infographics 2019</h1></td>
				<td><img src="img/quick_bar_chart_solid.png" width="180px"></td>
			</tr>
		</table>		
	</div>	
	<div class="menu">
		<table>
			<tr style="cursor: pointer;font-size: 18pt">
				<td onclick="update_view('home');">Home</td>
				<td onclick="update_view('tasks');">Tasks</td>
				<td onclick="update_view('schedule');">Schedule</td>
				<td onclick="update_view('data_tools');">Tools and Data</td>
				<td onclick="update_view('contact');">Contact Us</td>
			</tr>
		</table>
	</div>
	<div class="content">
		<div id="home" style="display: None;">
			<h1>Summary</h1>
			<p>
			This competition is composed of a series of 7 sub-tasks for chart data extraction, which when put together as a pipeline go from an input chart image to a CSV file representing the data used to create the chart.
			Entrants in the competition may choose to participate in any number of sub-tasks, which are evaluated in isolation, such that solving previous sub-tasks is not necessary.
			We hope that such decomposition of the problem of chart data extraction will draw broad participation from the Document Analysis and Recognition (DAR) community.
			Additionally, we also evaluate methods that perform the whole chart data extraction pipeline.
			</p>
			<h2>Background</h2>
			<p>
				Charts are a compact method of displaying and comparing data. In scientific publications, charts and graphs are often used to to summarize results, comparison of methodologies, emphasize the reasoning behind key aspects of the scientific process, and  justification of design choices, to name a few. Automatically extracting data from charts is a key step in understanding the intent behind a chart which could lead to a better understanding of the document itself. 
			</p>
			<table style="margin: auto;">
				<tr>
					<td><img src="img/charts.png" width="600px"></td>
				</tr>
				<tr>
					<td style="font-size: 10pt; text-align: center;">Example chart types to use in the proposed competition. Note that all these were generated from the same tabular data.</td>
				</tr>
			</table>
			
			<p>
				The DAR community has displayed a continued interest in classifying types of charts as well as processing charts to extract data. In the past decade, multiple applications have been built around automatic processing of charts such as retrieval, textual summarization of charts, making charts more accessible on the web, automatically redesigning charts, automatically assessing chart quality, preservation of charts from historical documents, chart data plagiarism detection, bibliometrics, visual question answering and accelerating discovery of new materials.
			</p>
			<p>
				Prior competitions related to this area include DeTEXT which concentrated on detecting text in figures and ImageCLEF competition on medical compound figure separation and multi-label classification. However, these competitions do not concentrate on end-to-end data extraction from scientific charts, but include these as a sub-type of scientific figures in general. 
			</p>
			
			<h2>Competition Outline</h2>
			<p>
			Both synthetic (created with matplotlib) and real charts (harvested from <a href='https://www.ncbi.nlm.nih.gov/pmc/'>PubMedCentral</a>) are provided as training data.
			Near the end of the competition, we will release test data, and competition participants are expected to send in 1) Method results on the test data 2) Summary of method 3) runnable code that can reproduce the results.
			The organizers will tabulate the overall results and the results for each sub-task to be presented at ICDAR 2019.
			</p>

			<p> The sub-tasks considered in this competition are </p>
				<ol>
					<li> Chart Image Classification (e.g. bar, box, line) </li>
					<li> Text Detection and Recognition </li>
					<li> Text Role Classification (e.g. title, x-axis label) </li>
					<li> Axis Analysis </li>
					<li> Legend Analysis </li>
					<li> Plot Area Analysis </li>
					<li> Data Extraction </li>
				</ol>
			<p> 
			Each subtask is evaluated in isolation, meaning that methods will have access to the ideal output (i.e. Ground Truth) of previous subtasks.
			For example, the input for the Axis Analysis sub-task is the chart image, chart type, and the text bounding boxes, transcriptions and roles.
			Each sub-task has its own evaluaton metric.
			</p>
			<p> Additionally, methods may be submitted for the complete data extraction task where subtasks 1-7 are performed together.  </p>

			<h2>Registration</h2>
			<p> To register, please send an email to chartinfo.icdar2019@gmail.com.  Please include the following. </p>
				<ul>
					<li> Names of participants </li>
					<li> Primary contact person </li>
					<li> Affiliation of participants </li>
					<li> Team Name </li>
					<li> List of tasks you are interested in participating in (you are not restricted to this list) </li>
				</ul>
			<p> Upon registration, you will be sent additional information to obtain the training and test data when it becomes available. </p>

			<!--
			<p>
				This competition is focused on data extraction and key element classification in charts used in scientific documents. More specifically, we have created a benchmark for axes charts (line, area, bar, box, and scatter plots) using a combination of synthetic data and figures from the PubMedCentral open access collection. Additionally, pie charts are considered in one sub-task (classification).

				The competition consists of multiple sub-tasks: chart image classification, extraction of text, text role classification, identifying legend and legend symbols, identifying chart marks such as lines, bars, and scatter marks, and finally extracting tabular data that originally produced the chart. These tasks are independent of each other and could potentially be chained to fulfill the overall task of extraction of tabular data from the chart. Metrics for each individual sub-task are derived from commonly used metrics for detection and classification such as recall-precision and accuracy. End-to-end competing systems will be evaluated on the basis of extraction of tabular data. 
			</p> -->
		</div>
		<div id="tasks" style="display: None;">
			<h1>Competition Tasks</h1>
			<p>
				The main task of the competition is to, given a chart image, extract the raw data that was used to create the chart image.
				We acknowledge that building an entire chart processing pipeline is time consuming, 
					so to encourage participation from the wider community, we divide the overall task into several smaller sub-tasks that can be solved in isolation.
				For each sub-task, the ground truth (GT) outputs of some previous sub-tasks are provided as input.
				<b>Researchers are encouraged to participate in as many or few sub-tasks as they like.</b>
				However, we also evaluate systems that perform the entire pipeline of sub-tasks without intermediate inputs.
			</p>
			<table style="margin: auto;">
				<tr>
					<td><img src="img/tasks.png" width="600px"></td>
				</tr>
			</table>
			<p>
				Note that since some partial ground truth will be provided for task with dependencies, 
					disjoint subsets of the test set will be used to evaluate these tasks independently for fairness. 
				For all tasks, the chart image is provided.
				Here is a list of the subtasks
			</p>
			<table style="margin:auto; width:100%; font-size:11pt; text-align:center">
				<tr> 
					<td> <a href="#task1">1) Chart Classification</a> </td> 
					<td> <a href="#task2">2) Text Detection/Recognition</a> </td> 
					<td> <a href="#task3">3) Text Role Classification</a> </td> 
					<td> <a href="#task4">4) Axis Analysis</a> </td> 
				</tr> <tr> 
					<td> <a href="#task5">5) Legend Analysis</a> </td> 
					<td> <a href="#task6a">6a) Plot Element Detection/Classification</a> </td> 
					<td> <a href="#task6b">6b) CSV Extraction</a> </td> 
					<td> <a href="#task7">7) End-to-End Data Extraction</a> </td> 
				</tr>
			</table>
			<a name='task1'><h2>1) Chart Image Classification</h2></a>
				<p> 
					Knowing the type of chart greatly affects what processing needs to be done.
					Thus, the first sub-task is to classify chart images by type. 
					Given the chart image, methods are expected to output one of the following 10 classes. 
				</p>
				<table style="margin:auto; width:100%; font-size:11pt; text-align:center">
					<tr>
						<td> Pie </td>
						<td> Donut </td>
						<td> Vertical box </td>
						<td> Horizontal box </td>
					</tr><tr>
						<td> Grouped vertical bar </td>
						<td> Grouped horizontal bar </td>
						<td> Stacked vertical bar </td>
						<td> Stacked horizontal bar </td>
					</tr><tr>
						<td> Line </td>
						<td> Scatter </td>
					</tr>
				</table>
				<p> Note that <b>pie and donut plots are not used</b> for the remaining sub-tasks. </p>

				<h3> Metric </h3>
					<p>
					The evaluation metric will be the <b>average per-class F-measure.</b>
					Based on the class confusion matrix, we can compute the precision, recall, and F-measure for each class.
					The overall score is the average of each classes' F-measure.
					</p>
				<h3> Input/Output </h3>
					<p> Input: Chart Image <p>
					<p> Output: Chart Class <p>

			<a name='task2'><h2>2) Text Detection and Recognition</h2></a>
				<p>
					Understanding the text in charts is necessary to interpret the graphical elements correctly.
					This sub-task concentrates on detecting and recognizing the text within the chart image. 
					Competing systems are expected to produce tight bounding boxes and transcriptions for each text block.
					Examples of individual text blocks individual titles, tick labels, legend labels.
					Text blocks may be a single line, multiple lines (due to text wrapping), and may be horizontal, vertical, or rotated.
					A predicted bounding box matches a GT bounding box if their Intersection Over Union (IOU) is at least 0.5, 
						and tighter IOU criteria will be used to resolve ties when multiple predictions can match a single GT bounding box.
					<!-- Evaluation metrics for detection of bounding boxes is precision-recall at Intersection Over Union (IOU) of 0.5. Tighter IOU criteria will be used to resolve ties. Same procedure as the ICDAR Robust Reading Competitions will be used to handle split/merged boxes. Transcription errors will be compared on the basis of edit distance from ground truth. -->
				</p>
				<h3> Metric </h3>
					<p> There are two evalaution metrics for detection and recognition respectively.
						For detection, we will sum the per-block <b>IOU</b> and divide by max(#predicted, #GT) for each image.
						For recognition, we will average <b>normalized Character Error Rate (CER)</b> for each text block in an image.
						By normalized CER, we mean that the number of character edits to transform a predicted word to GT word is divided by the length of the GT block.  
						False positive and false negative text block detections will be assigned a normalized CER of 1 and an IOU of 0.
						We will use the same procedure as the ICDAR Robust Reading Competitions to handle split/merged boxes.
					</p>
					<p>
						For each chart, we will compute both detection and recognition scores.
						Then we will average the per-chart scores over the whole dataset to ensure that each image contributes equally to the final score.
						The winner for the sub-task will be determined by the system with the highest harmonic mean of detection and recognition scores.
					</p>
				<h3> Input/Output </h3>
					<p> Input: Chart Image, Chart Class <p>
					<p> Output: List of (Text Block BB, Text Transcription) </p>

			<a name='task3'><h2>3) Text Role Classification</h2></a>
				<p>
					For text to be useful in chart interpretation, its semantic <i>role</i> should be identified.
					This sub-task focuses on identifying the role of each text block in a chart image, and text bounding boxes and transcripts are provided as input.
					Competing systems are expected to classify each bounding box into one of the following roles.
				</p>
				<table style="width:100%; font-size:11pt; text-align:center; align:center">
					<tr>
						<td> Chart title </td>
						<td> X-axis title </td>
						<td> Y-axis title </td>
					</tr><tr>
						<td> X-axis values (tick labels) </td>
						<td> Y-axis values (tick labels) </td>
						<td> Legend title </td>
					</tr><tr>
						<td> Legend label </td>
						<td> Plot label (e.g. data point labels) </td>
						<td> Other text </td>
					</tr>
				</table>
				<h3> Metric </h3>
					<p>Similar to the evaluation in sub-task 1 (chart classification), the evaluation metric will be the <b>average per-class F-measure.</b></p>

				<h3> Input/Output </h3>
					<p> Input: Chart Image, Chart Class, List of (Text Block BB, Text Transcription) </p>
					<p> Output: List of (Text Block BB, Text Transcription, Text role) </p>

			<a name='task4'><h2>4) Axis Analysis</h2></a>
				<p>
					Locating and interpreting the axes of the chart is critical to transforming data point coordinates from units of pixels to the semantic units.
					Competing systems are expected to output the location and value of each tick mark on both the X-axis and Y-axis.
					Tick locations are represented as points and must be associated with the corresponding value (a string).
					Note that some sets of ticks are ordered or unordered discrete sets with textual non-numeric labels.
				</p>
				<p>
					For this competition, X-axis will always refer to the axis that represents the independent variable shown, 
						rather than the axis that is visually horizontal.
					For example, vertical bar and vertical box plots have an X-axis that is vertical.
					Similarly, the Y-axis is not always the axis that is vertical.
				</p>
					
				<h3> Metric </h3>
					<p> TBD </p>

				<h3> Input/Output </h3>
					<p> Input: Chart Image, Chart Class, List of (Text Block BB, Text Transcription) </p>
					<p> Output: For each of X-axis and Y-axis, List of triples (tick x position, tick y position, tick value)</p>

			<a name='task5'><h2>5) Legend Analysis</h2></a>
				<p>
					The purpose of chart legends is to associate a data series name with the graphical style used to represent it
					This is critical to chart understanding when there are multiple data series represented.
				</p>
				<p>
					Competing systems are expected to associate each legend label text with the corresponding graphical style element within the legend area.
					Bounding boxes and transcriptions (but not text roles) are given as input.
					Note that in this task, legend labels are not paired with the corresponding data series found in the plot area.
					Also, some charts do not have legends.
				</p>
				<h3> Metric </h3>
					<p>
						For each GT legend label, if there is an associated predicted graphical style element, 
							we compute the <b>IOU</b> of the predicted BB to the GT graphical style element BB.
						We then divide the sum of the IOU by max(#predicted, #GT) for each image, and then average this value over all images.
					</p>
				<h3> Input/Output </h3>
					<p> Input: Chart Image, Chart Class, List of (Text Block BB, Text Transcription) </p>
					<p> Output: A list of (Text BB, Transcription, Graphical Style Element BB) </p>

			<h2>6) Data Extraction</h2>
				<p>
					The goal of this task is to convert all of the previously extracted information into a CSV file.
					We break this task into 2 subtasks: (a) plot element detection and classification (b) data conversion.
					Competitor systems are expected to produce output for both sub-tasks.
					It is also permitted for competitors to only perform this sub-task only for certain classes of charts.
				</p>
			<a name='task6a'><h2>6a) Plot Element Detection/Classification</h2></a>
				<p>
					For 6a, the subtask of visual analysis, the goal is to detect and classify each individual element in the plot area.
					The representation of the element varies by class and is listed in the table below.
					Note that the output representations (BB or point) are in units of pixels.
				</p>
				<table style="width:100%; font-size:11pt; text-align:center; align:center">
					<tr> <th> Element Class</th> <th> Description </th> <th> Representation </th> </tr>
					<tr> <td> Bar </td> <td> Individual bars in bar charts </td> <td> Bounding Box </td> </tr>
					<tr> <td> Line Point </td> <td> Location of Data Points in line charts </td>  <td> Point </td> </tr>
					<tr> <td> Scatter Marker </td> <td> Location of Data Points in scatter charts </td>  <td> Point </td> </tr>
					<tr> <td> Boxplot Median </td> <td> Median Line of Boxplot </td>  <td> Point </td> </tr>
					<tr> <td> Boxplot Box Top </td> <td> Line that is typically the upper quartile</td>  <td> Point </td> </tr>
					<tr> <td> Boxplot Box Bottom </td> <td> Line that is typically the lower quartile</td>  <td> Point </td> </tr>
					<tr> <td> Boxplot Top Wisker </td> <td> Line that is typically the max value</td>  <td> Point </td> </tr>
					<tr> <td> Boxplot Bottom Wisker </td> <td> Line that is typically the min value</td>  <td> Point </td> </tr>
				</table>
				<p> 
					Even though boxplot elements are visually line segments, we allow for any point on that line segment.  
					Other plot elements, such as boxplot outlier points, are not evaluated and should not be contained in the output for this sub-task.
					Note that the chart class is given as input to this task and that each plot element can be found in only one class of chart.
				</p>
				<h3> Metric </h3>
					<p>
						For an element to be correctly detected, it must be <b>assigned to the correct class.</b>
						We will use a variation on MSE to evaluate the representation of each element with the correct class.
						For each element, we compute a score between 0 and 1, where 1 represents an exact prediction, 
							and predictions farther away than a distance threshold, T, receive a score of 0.
						<b>The score is max(0, 1 - (D/T)^2)</b>, where D is the Euclidean distance between the predicted and GT points.
						The distance threshold, T, is determined to be 5% of the smallest image dimension.
						Because there are many ways to pair predicted and GT points, we will find the minimum cost pairing
							(i.e. sovle this bi-partite graph matching problem).
					</p>
					<p> 
						For Boxplot elements, we will use <b>distance between the predicted point and the line segment.</b>
						For Bar chart bars, we will use the <b>distances between corresponding BB corners.</b>
					</p>
					<p> For each chart, the scores will be summed and divided by max(#GT, #Predictions).  Then these scores will be averaged across all images. </p>

				<h3> Input/Output </h3>
					<p> Input: Outputs of tasks 1-5 </p>
					<p> Output: List of (Element Class, Element Representation) </p>

			<a name='task6b'><h2>6b) Raw Data Extraction</h2></a>
				<p>
					Output the raw data that was used to generate the chart image.
					For the purpose of this competition, we define a simple schema, where each chart is a set of data series, 
						and a data series is a name (string) and a list of (x,y) points.
					The x values can be either numerical or string values, depending on the X-axis domain.
					The y values are always numerical.
				</p>
				<p>
					For box plots, it is not necessary to reproduce the raw data as the plot only shows a statistical summary.  
					Instead, participants are expected to recover the dataset median, upper and lower quartiles, and wisker values.
					The interpretation of the wiskers (e.g. dataset min/max or 2/98 percentiles) is not always contained in the chart image itself,
						so we do not require this information at any stage of the competition.
				</p>
				<h3> Metric </h3>
					<p>
						Data Series names should come from the chart legend (if there is one).  
						If the data series names are not specified in the chart image, then the predicted names are <b>ignored for evaluation purposes</b>.
					</p>

					<p> TBD </p>

				<h3> Input/Output </h3>
					<p> Input: Outputs of tasks 1-5. </p>
					<p> Output: Set of Data Series.  Data Series = (name, [(x_1, y_1), ..., (x_n, y_n)]) </p>
					<p> The output of 6a is <b>not</b> given as an input to 6b. </p>

			<a name='task7'><h1>End-to-End Data Extraction</h1></a>
			<p>
				This is the main task of the competition and involves producing the CSV file directly from the chart image without any intermediate inputs.
				The competing systems will be evaluated on the metric for subtask 6b, and are free to use third party software (e.g. for OCR).
			</p>
				<h3> Metric </h3>
					<p>See Metric for sub-task 6b.</p>

				<h3> Input/Output </h3>
					<p> Input: Chart Image. </p>
					<p> Output: See output of sub-task 6b. </p>
		</div>
		<div id="schedule" style="display: None;">
			<h1>Competition Schedule</h1>
			<p>
				Coming Soon.
			</p>
		</div>
		<div id="data_tools" style="display: None;">
			<h1>Tools and Data</h1>
			<p>
				Coming Soon.
			</p>
		</div>
		<div id="contact" style="display: None;">
			<h1>Registration and Contact Information</h1>
			<p>
				For any inquiries, please email us at chartinfo.icdar2019@gmail.com.
			</p>

			<h2>Registration</h2>
			<p> To register, please send an email to chartinfo.icdar2019@gmail.com.  Please include the following. </p>
				<ul>
					<li> Names of participants </li>
					<li> Primary contact person </li>
					<li> Affiliation of participants </li>
					<li> Team Name </li>
					<li> List of tasks you are interested in participating in (you are not restricted to this list) </li>
				</ul>
			<p> Upon registration, you will be sent additional information to obtain the training and test data when it becomes available. </p>

			<h2> Organizer Information </h2>
		</div>
	</div>
  </div>
  <script>
	update_view("home");
  </script>
</body>
</html>
